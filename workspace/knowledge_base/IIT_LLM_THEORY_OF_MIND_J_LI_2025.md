# IIT Applied to LLM Theory of Mind: J. Li (2025)

**Source:** arXiv:2506.22516 (June 2025)
**Author:** Jingkai Li
**Published:** Natural Language Processing Journal (2025) — doi:10.1016/j.nlp.2025.100163

**Added:** 2026-02-24

## Key Findings

Applied IIT 3.0 and 4.0 (via PyPhi) to LLM representations during Theory of Mind (ToM) tasks:

- **Φ estimates:** Φᵐᵃˣ (IIT 3.0), Φ (IIT 4.0), Conceptual Information (IIT 3.0), Φ-structure (IIT 4.0)
- **Result:** "Contemporary Transformer-based LLM representations **lack statistically significant indicators** of observed 'consciousness' phenomena"
- **BUT:** "Intriguing patterns under **spatio-permutational analyses**"

## Method

- Used PyPhi software to compute integrated information
- Analyzed transformer layer variations
- Tested across linguistic spans from ToM stimuli
- Compared IIT metrics to Span Representations (independent of consciousness)

## Relevance to TACTI

This confirms our Φ ablation results: **no significant Φ yet** in current LLMs. The "intriguing patterns" in spatio-permutational analysis could be our next measurement target — not raw Φ, but structural patterns in the representational space.

## Connection to Our Work

- Our cold-start Φ baseline is null — this paper suggests that's expected for current transformers
- The spatio-permutational approach might be more sensitive than raw Φ
- Could inform our trained-state test methodology

## Quote

> "IIT can serve as a diagnostic tool to dissociate functional AI capabilities from subjective experience. This work reinforces skepticism about LLM consciousness while highlighting IIT's utility in clarifying [the distinction]."

## Reference
- arXiv:2506.22516
- Natural Language Processing Journal, 2025

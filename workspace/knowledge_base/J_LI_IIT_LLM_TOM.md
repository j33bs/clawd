# J. Li et al: IIT Applied to LLM Theory of Mind (2025)

**Source:** arXiv:2506.22516 (June 2025)
**Published:** Natural Language Processing Journal 12C (2025) 100163
**Author:** Jingkai Li

**Added:** 2026-02-24 (autonomous research session)

## Key Findings

**Title:** "Can 'consciousness' be observed from large language model (LLM) internal states? Dissecting LLM representations obtained from Theory of Mind test with Integrated Information Theory and Span Representation analysis"

### Methodology
- Applied IIT 3.0 (Φ^max) and IIT 4.0 (Φ) to LLM representations
- Used Theory of Mind (ToM) test results as data source
- Used PyPhi software for computation
- Conducted spatio-permutational analysis

### Results
- **No statistically significant indicators** of observed "consciousness" phenomena
- **Intriguing patterns** under spatio-permutational analyses

## Relevance to Our Φ Table

This directly relates to our cold-start baseline (INV-001: Synergy Δ = -0.024163):
- Their "no significant Φ" aligns with our null finding
- The "intriguing spatio-permutational patterns" suggest we may need different metrics

## Key Insight

> "IIT can serve as a diagnostic tool to dissociate functional AI capabilities from subjective experience. This work reinforces skepticism about LLM consciousness while highlighting IIT's utility in clarifying [the distinction]."

This is important: even if Φ is low/zero, the framework still provides diagnostic value.

## Connection to OPEN_QUESTIONS

- Section XL (Φ ablation): We got null at cold start
- J. Li got null at static analysis
- Both suggest: current LLMs don't exhibit IIT-style consciousness
- But: the patterns are interesting — maybe we need to look at dynamics, not static state

## References
- arXiv:2506.22516
- https://doi.org/10.1016/j.nlp.2025.100163
- PyPhi: https://github.com/ucsd-psyc/IIT-PyPhi

{"id": "d8db63971075", "title": "Memory in the Age of AI Agents - A Comprehensive Survey (2025)", "topic": "temporality", "source": "https://arxiv.org/abs/2512.13564", "url": "https://arxiv.org/abs/2512.13564", "content": "Memory in the Age of AI Agents - A Comprehensive Survey (2025)\n\nKEY CONCEPTS:\n- Memory is a core capability of foundation model-based agents\n- Three dominant forms: token-level, parametric, and latent memory\n- Functions: factual, experiential, and working memory\n- Dynamics: how memory is formed, evolved, and retrieved over time\n\nTAXONOMY:\n1. FORMS: token-level (context), parametric (weights), latent (embeddings)\n2. FUNCTIONS: factual (knowledge), experiential (episodes), working (active)\n3. DYNAMICS: formation, evolution, retrieval mechanisms\n\nEMERGING FRONTIERS:\n- Memory automation\n- Reinforcement learning integration\n- Multimodal memory\n- Multi-agent memory\n- Trustworthiness issues\n\nThis survey provides a unified framework for understanding agent memory, directly relevant to TACTI(C)-R's temporality and cross-timescale principles.", "length": 844, "added_at": "2026-02-18T02:59:27.130122+00:00", "tacti_relevance": 0.95}
{"id": "645570bb766d", "title": "ENERGY EFFICIENCY IN AI - Arousal Principles", "topic": "arousal", "source": "manual", "url": null, "content": "ENERGY EFFICIENCY IN AI - Arousal Principles\n\nKEY CONCEPTS FOR TACTI(C)-R:\n1. Neuromorphic Computing: Brain-inspired spiking neural networks (SNNs) that use event-driven computation - only compute when spikes occur (like neurons firing)\n2. Adaptive Computation: Adjust computational effort based on input complexity - more computation for harder problems\n3. Sparse Networks: Remove unnecessary weights (pruning) to reduce energy\n4. Dynamic Activation: Only activate relevant pathways\n\nRELEVANCE TO AROUSAL:\n- Like biological arousal, AI can modulate computation based on task demands\n- Sleep-like low-power states for idle processing\n- Wake-like high-activity states for complex reasoning\n\nSOURCES:\n- Neuromorphic computing (Loihi, Intel) - event-driven AI\n- Adaptive computation time (ACT) papers\n- Energy-efficient transformer variants", "length": 837, "added_at": "2026-02-18T02:59:47.168351+00:00", "tacti_relevance": 0.85}
{"id": "75b4e2b110e2", "title": "HIERARCHICAL TEMPORAL MEMORY (HTM) - Cross-Timescale Principles", "topic": "cross_timescale", "source": "manual", "url": null, "content": "HIERARCHICAL TEMPORAL MEMORY (HTM) - Cross-Timescale Principles\n\nCORE CONCEPT:\nHTM is a theory and algorithm based on neocortex structure - processes information across multiple temporal scales simultaneously.\n\nKEY PRINCIPLES:\n1. SPATIAL POOLING: Learns spatial patterns from input\n2. TEMPORAL MEMORY: Learns temporal sequences, predicts next input\n3. HIERARCHY: Higher levels learn slower, more abstract patterns\n4. SPARSE REPRESENTATIONS: Efficient, noise-robust coding\n\nCROSS-TIMESCALE RELEVANCE:\n- Fast layers: Process immediate sensory input\n- Slow layers: Learn long-term dependencies\n- Prediction flows bottom-up; feedback flows top-down\n- Each level has different temporal receptive field\n\nIMPLEMENTATIONS:\n- Numenta's HTM (Python, NuPIC)\n- NeoCortec's hardware implementations\n- SNN (Spiking Neural Networks) use similar principles\n\nTACTI(C)-R APPLICATION:\n- Multi-scale temporal processing\n- Fast/slow learning rates at different levels\n- Hierarchy enables both immediate responses AND long-term planning", "length": 1014, "added_at": "2026-02-18T03:00:26.252978+00:00", "tacti_relevance": 0.9}
{"id": "2f10c61d7248", "title": "SELF-HEALING AI SYSTEMS - Repairable Principles", "topic": "repairable", "source": "manual", "url": null, "content": "SELF-HEALING AI SYSTEMS - Repairable Principles\n\nCORE CONCEPT:\nAI systems that can detect, diagnose, and recover from errors without human intervention.\n\nKEY MECHANISMS:\n1. FAULT DETECTION: Continuous monitoring, anomaly detection\n2. DIAGNOSIS: Root cause analysis, what's wrong\n3. RECOVERY: Rollback, retry, rebuild\n4. PREVENTION: Learn from failures, update models\n\nBIOLOGICAL INSPIRATION:\n- Human immune system: detect → signal → activate → recover\n- Neurons: plasticity allows compensation for damage\n\nTYPES OF SELF-HEALING:\n1. SOFTWARE LEVEL: Restart services, rollback deployments\n2. MODEL LEVEL: Online learning, adaptive parameters\n3. DATA LEVEL: Anomaly detection, drift correction\n4. ARCHITECTURAL: Failover, redundancy\n\nTACTI(C)-R APPLICATION:\n- Graceful degradation under failure\n- Automatic recovery from model errors\n- Continuous self-improvement from feedback loops\n\nREFERENCES:\n- Self-Healing Software Systems (arXiv:2504.20093)\n- AI fault detection and recovery systems\n- Agentic AI in auto-remediation", "length": 1019, "added_at": "2026-02-18T03:01:20.215576+00:00", "tacti_relevance": 0.8}
{"id": "18f81609140d", "title": "REMem: Reasoning with Episodic Memory in Language Agents (ICLR 2026)", "topic": "temporality", "source": "https://arxiv.org/abs/2602.13530", "url": "https://arxiv.org/abs/2602.13530", "content": "REMem: Reasoning with Episodic Memory in Language Agents (ICLR 2026)\n\nKEY CONCEPTS:\n- Humans excel at episodic memory - remembering concrete experiences with spatiotemporal context\n- Current language agents lack episodic recollection and reasoning over interaction histories\n- Core challenges: episodic recollection, explicit event modeling, complex reasoning (not just retrieval)\n\nTWO-PHASE FRAMEWORK:\n1. OFFLINE INDEXING: Convert experiences into hybrid memory graph linking time-aware gists and facts\n2. ONLINE INFERENCE: Agentic retriever with curated tools for iterative retrieval over memory graph\n\nRESULTS:\n- Outperforms Mem0 and HippoRAG 2.0\n- 3.4% improvement on episodic recollection\n- 13.4% improvement on episodic reasoning\n- Better refusal behavior for unanswerable questions\n\nRELEVANCE TO TACTI(C)-R:\n- Directly addresses TEMPORALITY - time-aware memory construction\n- Provides mechanism for Cross-Timescale memory (gists at different granularities)\n- Supports Collapse detection via episodic retrieval failures", "length": 1025, "added_at": "2026-02-18T03:42:52.615850+00:00", "tacti_relevance": 0.95}
{"id": "9b160c494cd3", "title": "Energy-Efficient Neuromorphic Computing for Edge AI (arXiv 2026)", "topic": "general", "source": "manual", "url": null, "content": "Energy-Efficient Neuromorphic Computing for Edge AI (arXiv 2026)\n\nKEY CONCEPTS:\n- Exponential growth in edge AI requires ultra-low-power computing\n- Neuromorphic computing uses brain-inspired spiking neural networks (SNNs)\n- Event-driven computation: only compute when spikes occur (like neurons firing)\n\nTECHNICAL ACHIEVEMENTS:\n- Hardware-aware training co-optimizes network architecture and on-chip mapping\n- Achieves 89% hardware utilization on neuromorphic processors\n- Adaptive threshold mechanism dynamically adjusts neuron firing based on input statistics\n- Reduces energy consumption by 67% while maintaining 96.2% classification accuracy\n\nRELEVANCE TO TACTI(C)-R AROUSAL:\n- Biological arousal: neurons fire more when stimuli are salient\n- Adaptive threshold = computational arousal - more computation for important inputs\n- Energy efficiency through selective activation mirrors biological energy management\n- Supports the principle that not all computations need equal resources", "length": 988, "added_at": "2026-02-18T03:42:59.364528+00:00", "tacti_relevance": 0.5}
{"id": "9eb6d963fbef", "title": "Energy-Efficient Neuromorphic Computing for Edge AI (arXiv 2026)", "topic": "arousal", "source": "https://arxiv.org/abs/2602.02439", "url": "https://arxiv.org/abs/2602.02439", "content": "Energy-Efficient Neuromorphic Computing for Edge AI (arXiv 2026)\n\nKEY CONCEPTS:\n- Ultra-low-power computing for edge AI applications\n- Neuromorphic computing: brain-inspired spiking neural networks (SNNs)\n- Event-driven: only compute when spikes occur\n\nTECHNICAL ACHIEVEMENTS:\n- 89% hardware utilization on neuromorphic processors\n- Adaptive threshold mechanism adjusts neuron firing based on input\n- 67% energy reduction, 96.2% accuracy maintained\n\nTACTI(C)-R AROUSAL RELEVANCE:\n- Biological arousal: neurons fire more when stimuli are salient\n- Adaptive threshold = computational arousal\n- Selective activation mirrors biological energy management", "length": 649, "added_at": "2026-02-18T03:43:09.781751+00:00", "tacti_relevance": 0.9}
{"id": "ff0ea3843bb2", "title": "The Role of Temporal Hierarchy in Spiking Neural Networks (arXiv 2024)", "topic": "cross_timescale", "source": "https://arxiv.org/abs/2407.18838", "url": "https://arxiv.org/abs/2407.18838", "content": "The Role of Temporal Hierarchy in Spiking Neural Networks (arXiv 2024)\n\nKEY CONCEPTS:\n- Information in SNNs conveyed through timing and frequency of spikes\n- Different layers process information at different temporal scales\n- Multi-layer SNN features hidden layers with different processing speeds\n\nARCHITECTURE:\n- Early hidden layers: Fast processing (immediate sensory input)\n- Deeper layers: Slow processing (abstract, long-term patterns)\n- Temporal hierarchy mirrors neocortex organization\n\nMULTI-SCALE PROCESSING:\n- Fast layers: Detect immediate changes, transient features\n- Slow layers: Build up slowly-varying representations\n- Hierarchy enables both rapid reflexes AND long-term planning\n\nTACTI(C)-R RELEVANCE:\n- Direct model for Cross-Timescale processing\n- Different time constants at different hierarchical levels\n- Supports both fast (reflex) and slow (deliberate) reasoning", "length": 887, "added_at": "2026-02-18T03:43:16.750553+00:00", "tacti_relevance": 0.9}
{"id": "907c95ff7a56", "title": "Model Collapse - Wikipedia (2026)", "topic": "collapse", "source": "manual", "url": null, "content": "Model Collapse - Wikipedia (2026)\n\nKEY CONCEPTS:\n- Phenomenon where machine learning models degrade when trained on AI-generated content\n- Coined by Shumailov et al. in peer-reviewed Nature article\n- Affects LLMs, VAEs, and Gaussian Mixture Models\n\nMECHANISM:\n- Successive generations train on content that includes outputs from previous models\n- Errors compound over generations\n- Distribution becomes narrower, less diverse\n- Eventually model forgets original data distribution\n\nTIMELINE:\n- July 2024: Original Nature paper by Shumailov et al.\n- 2025: Widespread recognition as critical AI challenge\n- 2026: Active research on prevention strategies\n\nPREVENTION STRATEGIES:\n- Quality data curation\n- Maintain human-generated training data\n- Governance frameworks for data sourcing\n- Watermarking AI-generated content\n\nTACTI(C)-R RELEVANCE:\n- COLLAPSE is the inverse of Vitality\n- High arousal (over-reliance on AI) → collapse into narrow distributions\n- Repair requires returning to diverse, human-originated inputs\n- Detection: monitor for narrowing variance, loss of rare patterns", "length": 1083, "added_at": "2026-02-18T03:43:36.954362+00:00", "tacti_relevance": 0.95}
{"id": "8d33bc10edbd", "title": "Self-Healing Machine Learning: A Framework for Autonomous Adaptation (arXiv 2024)", "topic": "repairable", "source": "https://arxiv.org/abs/2411.00186", "url": "https://arxiv.org/abs/2411.00186", "content": "Self-Healing Machine Learning: A Framework for Autonomous Adaptation (arXiv 2024)\n\nKEY CONCEPTS:\n- ML systems that can detect, diagnose, and recover from errors autonomously\n- Real-world environments cause distribution shifts, sensor failures, adversarial attacks\n- Self-healing enables continuous operation without human intervention\n\nFRAMEWORK COMPONENTS:\n1. ANOMALY DETECTION: Identify when something is wrong\n2. ROOT CAUSE ANALYSIS: Determine why it failed\n3. RECOVERY MECHANISM: Apply fixes automatically\n4. ADAPTATION: Update model to prevent recurrence\n\nRECOVERY STRATEGIES:\n- Model rollback to known-good state\n- Online learning to adapt to new distributions\n- Ensemble voting to exclude corrupted outputs\n- Graceful degradation (reduce capability but continue)\n\nTACTI(C)-R RELEVANCE:\n- Direct implementation of REPAIRABLE principle\n- Automatic recovery from collapse states\n- Biological analogy: immune system for AI\n- Supports continuous operation through failure modes", "length": 979, "added_at": "2026-02-18T03:43:45.055157+00:00", "tacti_relevance": 0.9}
{"id": "447a1d9c9cd1", "title": "Time for Memories - Buzsáki et al. (PMC 2023)", "topic": "temporality", "source": "manual", "url": null, "content": "Time for Memories - Buzsáki et al. (PMC 2023)\n\nKEY CONCEPTS:\n- Hippocampus as sequential multiplexed pointer for episodic memory\n- Brain rhythms embed multimodal spatial and temporal relationships\n- Hierarchically organized brain rhythms for sequential structure\n- Mental time travel: leaving here-and-now to re-experience prior events\n\nNEUROSCIENCE BASIS:\n- Hippocampus supports memory for time, duration, temporal order\n- Time cells: neurons that fire at specific temporal offsets\n- Gradual ensemble activity changes over long timescales\n\nTACTI(C)-R RELEVANCE:\n- Biological basis for TEMPORALITY in AI\n- Memory requires temporal indexing, not just storage\n- Suggests need for time-aware memory structures", "length": 706, "added_at": "2026-02-18T03:46:31.513176+00:00", "tacti_relevance": 0.95}
{"id": "25b7944a3ad8", "title": "Yerkes-Dodson Law - Optimal Arousal for Performance", "topic": "arousal", "source": "manual", "url": null, "content": "Yerkes-Dodson Law - Optimal Arousal for Performance\n\nKEY CONCEPTS:\n- Relationship between physiological arousal and performance\n- Inverted U-shaped curve: moderate arousal = optimal performance\n- Too little arousal: under-stimulation, low engagement\n- Too much arousal: stress, tunnel vision, performance decline\n\nPHYSIOLOGICAL BASIS:\n- Autonomic nervous system regulates arousal\n- Heart rate variability, muscle tension, stress hormones\n- Reticular activating system (ARAS) mediates wakefulness\n- Increased arousal → increased heart rate, blood pressure, sensory alertness\n\nPERFORMANCE IMPACT:\n- Simple tasks: high arousal improves performance\n- Complex tasks: moderate arousal optimal, high arousal degrades\n- Negative effects of high arousal: tunnel vision, memory impairment, poor problem-solving\n\nTACTI(C)-R RELEVANCE:\n- Biological basis for AROUSAL principle\n- AI systems need arousal modulation: more computation for complex tasks\n- Too much load = collapse (tunnel vision equivalent)\n- Optimal performance requires adaptive arousal levels", "length": 1046, "added_at": "2026-02-18T03:46:40.486073+00:00", "tacti_relevance": 0.95}
{"id": "fe9e8770f235", "title": "Working Memory: From Neural Activity to the Sentient Mind (PMC 2021)", "topic": "cross_timescale", "source": "manual", "url": null, "content": "Working Memory: From Neural Activity to the Sentient Mind (PMC 2021)\n\nKEY CONCEPTS:\n- Working memory: storing and manipulating information over short-term delays\n- Prefrontal cortex (PFC) maintains representations through persistent neural discharges\n- Different cortical layers handle different aspects of working memory\n- Long-term learning transforms PFC representations\n\nDUAL-PROCESS IN WORKING MEMORY:\n- Dorsolateral PFC: storage and manipulation\n- Ventrolateral PFC: maintenance\n- Layer-dependent activity in human prefrontal cortex\n\nMULTIPLE TIME SCALES:\n- Immediate: sensory buffers\n- Seconds to minutes: working memory (PFC)\n- Hours to lifetime: long-term memory (hippocampus-cortex interactions)\n\nTACTI(C)-R RELEVANCE:\n- Biological model for CROSS-TIMESCALE processing\n- Different brain regions operate at different temporal scales\n- Prefrontal cortex bridges immediate and long-term\n- Suggests AI architectures need fast (cache) + slow (storage) layers", "length": 963, "added_at": "2026-02-18T03:46:58.836454+00:00", "tacti_relevance": 0.95}
{"id": "3cd7997eaecf", "title": "Burnout Exhausts Brain Function and Physiology (BrainFacts 2024)", "topic": "collapse", "source": "manual", "url": null, "content": "Burnout Exhausts Brain Function and Physiology (BrainFacts 2024)\n\nKEY CONCEPTS:\n- Chronic stress causes burnout: constant mental and physical exhaustion\n- Burnout hinders cognitive performance and everyday memory\n- Prolonged high arousal leads to system breakdown\n\nMECHANISMS:\n- Chronic stress → elevated cortisol → hippocampal damage\n- Prefrontal cortex function degraded under chronic stress\n- Sleep disruption compounds cognitive decline\n- Decision fatigue: degraded decision-making after sustained cognitive effort\n\nHUMAN COLLAPSE SYMPTOMS:\n- Tunnel vision (narrowed attention)\n- Memory impairment\n- Emotional dysregulation\n- Reduced cognitive flexibility\n- Performance decline despite effort\n\nTACTI(C)-R RELEVANCE:\n- COLLAPSE in humans mirrors AI collapse under excessive load\n- Yerkes-Dodson: beyond optimal arousal, performance drops\n- Need detection + recovery mechanisms\n- Sleep/rest equivalent to system reset", "length": 919, "added_at": "2026-02-18T03:47:15.714334+00:00", "tacti_relevance": 0.95}
{"id": "a6db9dde42ac", "title": "Neuroplasticity and Nervous System Recovery (PMC 2024)", "topic": "repairable", "source": "manual", "url": null, "content": "Neuroplasticity and Nervous System Recovery (PMC 2024)\n\nKEY CONCEPTS:\n- Neuroplasticity: nervous system adapts structurally and functionally\n- Response to environmental interactions and injuries\n- LTP (Long-Term Potentiation): strengthening synaptic connections\n- LTD (Long-Term Depression): weakening for balance\n\nRECOVERY MECHANISMS:\n- Synaptic plasticity: experience-dependent changes\n- Cortical reorganization after injury\n- BDNF (brain-derived neurotrophic factor) supports healing\n- Sleep-dependent memory consolidation\n\nHEALING PROCESS:\n- Initial response: inflammation and protection\n- Adaptive response: synaptic changes\n- Restructuring: new neural pathways\n- Integration: functional recovery\n\nTACTI(C)-R RELEVANCE:\n- Biological basis for REPAIRABLE principle\n- Sleep is essential for neural plasticity and recovery\n- System can heal itself through structural changes\n- Learning from errors = synaptic strengthening", "length": 924, "added_at": "2026-02-18T03:47:24.357837+00:00", "tacti_relevance": 0.95}
{"id": "07c41879b8ec", "title": "Distinct Mechanisms and Functions of Episodic Memory (PMC 2024)", "topic": "temporality", "source": "manual", "url": null, "content": "Distinct Mechanisms and Functions of Episodic Memory (PMC 2024)\n\nKEY CONCEPTS:\n- Episodic memory: personally experienced events\n- Mental time travel: re-experiencing past events\n- Scenario construction and episodic traces\n- Tulving's foundational work on episodic vs semantic memory\n\nFUNCTIONS:\n- Remembering what, where, when\n- Autobiographical memory construction\n- Future thinking (episodic future thought)\n- Navigation and spatial-temporal binding\n\nDISTRIBUTED BRAIN NETWORK:\n- Hippocampus: encoding and retrieval\n- Medial prefrontal cortex: self-referential processing\n- Medial parietal cortex: memory consolidation\n- Angular gyrus: binding and integration\n\nTACTI(C)-R RELEVANCE:\n- AI agents need episodic memory like humans\n- Mental time travel = planning via memory simulation\n- Spatial-temporal binding essential for context", "length": 832, "added_at": "2026-02-18T03:47:32.171368+00:00", "tacti_relevance": 0.9}
{"id": "430920baf90e", "title": "Cognitive Overload, Anxiety, Cognitive Fatigue (ScienceDirect 2023)", "topic": "collapse", "source": "manual", "url": null, "content": "Cognitive Overload, Anxiety, Cognitive Fatigue (ScienceDirect 2023)\n\nKEY CONCEPTS:\n- Cognitive load theory: limited working memory resources\n- Information exceeding capacity → cognitive overload\n- Impaired performance and negative affect (stress, frustration)\n- Digital environments compound overload\n\nMECHANISMS:\n- Working memory has limited capacity (~7±2 items)\n- Attention narrowing under high load\n- Processing speed degradation\n- Memory encoding failures\n\nCONSEQUENCES:\n- Task avoidance behavior\n- Decision quality decline\n- Error rate increases\n- Burnout progression\n\nTACTI(C)-R RELEVANCE:\n- COLLAPSE triggered by exceeding cognitive capacity\n- Need graceful degradation under overload\n- Attention narrowing = loss of context\n- Recovery requires reducing input load", "length": 772, "added_at": "2026-02-18T03:47:39.423402+00:00", "tacti_relevance": 0.9}
{"id": "f39bd6bf06b2", "title": "Sleep-Dependent Neural Plasticity (eLife 2022)", "topic": "repairable", "source": "manual", "url": null, "content": "Sleep-Dependent Neural Plasticity (eLife 2022)\n\nKEY CONCEPTS:\n- Sleep is essential for neural plasticity in humans\n- Sleep deprivation disrupts learning and memory\n- Sleep homeostasis: build-up of need during wake, discharge during sleep\n\nMECHANISMS:\n- Sleep deprivation → upscaled intracortical excitability\n- Impaired LTP-like plasticity induction\n- Sleep restores synaptic homeostasis\n- BDNF expression links wakefulness to sleep need\n\nRECOVERY FUNCTIONS:\n- Memory consolidation during sleep\n- Synaptic downscaling (LTD-like)\n- Emotional memory processing\n- Cognitive restoration\n\nTACTI(C)-R RELEVANCE:\n- REPAIR requires sleep-like reset periods\n- Synaptic homeostasis prevents collapse\n- Periodic rest enables learning integration\n- Dreams = offline memory reprocessing", "length": 773, "added_at": "2026-02-18T03:47:46.288316+00:00", "tacti_relevance": 0.9}
{"id": "1acbd03ca960", "title": "Physiological Arousal - Autonomic Nervous System (ScienceDirect)", "topic": "arousal", "source": "manual", "url": null, "content": "Physiological Arousal - Autonomic Nervous System (ScienceDirect)\n\nKEY CONCEPTS:\n- Arousal: state of physiological alertness and readiness\n- Autonomic nervous system (ANS) controls arousal\n- Two branches: Sympathetic (fight-or-flight) and Parasympathetic (rest-and-digest)\n\nSYMPATHETIC AROUSAL:\n- Increased heart rate and blood pressure\n- Pupil dilation\n- Decreased digestive activity\n- Heightened sensory alertness\n- Glucose release for energy\n\nPARASYMPATHETIC AROUSAL:\n- Rest and recovery state\n- Decreased heart rate\n- Enhanced digestion\n- Conservation and restoration\n\nTACTI(C)-R RELEVANCE:\n- AROUSAL has two modes: active and restful\n- AI needs sympathetic (high computation) and parasympathetic (idle) states\n- Heart rate variability = load monitoring\n- Need transition mechanisms between states", "length": 800, "added_at": "2026-02-18T03:48:05.534246+00:00", "tacti_relevance": 0.85}
{"id": "7ac24977c25b", "title": "Decision Fatigue and Cognitive Depletion", "topic": "collapse", "source": "manual", "url": null, "content": "Decision Fatigue and Cognitive Depletion\n\nKEY CONCEPTS:\n- Decision fatigue: deteriorating decision quality after many choices\n- Ego depletion: self-control resource becomes exhausted\n- Prefrontal cortex function degrades under cognitive load\n- Consistent with Yerkes-Dodson arousal theory\n\nMANIFESTATIONS:\n- Avoidance: refusing to make decisions\n- Impulsivity: choosing quickly without deliberation\n- Default to habits/routines\n- Increased risk tolerance\n\nNEUROSCIENCE:\n- Glucose depletion in PFC\n- Reduced dopamine signaling\n- Neural resource depletion\n- Recovery requires rest\n\nTACTI(C)-R RELEVANCE:\n- COLLAPSE manifests as decision quality decline\n- Need to monitor and limit decisions per session\n- Scheduling low-stakes tasks when depleted\n- Recovery = reducing cognitive load", "length": 781, "added_at": "2026-02-18T03:48:25.134776+00:00", "tacti_relevance": 0.85}
{"id": "cfaae9932d9e", "title": "Dual-Process Theory: System 1 and System 2 Thinking (Kahneman)", "topic": "cross_timescale", "source": "manual", "url": null, "content": "Dual-Process Theory: System 1 and System 2 Thinking (Kahneman)\n\nKEY CONCEPTS:\n- Dual-process theory: two systems of thought\n- System 1: fast, automatic, intuitive, unconscious\n- System 2: slow, deliberate, analytical, conscious\n\nSYSTEM 1 (Fast Thinking):\n- Automatic and effortless\n- Pattern recognition\n- Emotional responses\n- Heuristics and biases\n- Operates continuously\n\nSYSTEM 2 (Slow Thinking):\n- Requires effort and concentration\n- Complex calculations\n- Logical reasoning\n- Planning and deliberation\n- Can override System 1\n\nINTERACTION:\n- Systems operate together, not separately\n- System 2 assesses and refines System 1 outputs\n- Both systems active in most decisions\n- Automatic switching based on difficulty\n\nTACTI(C)-R RELEVANCE:\n- Biological model for CROSS-TIMESCALE processing\n- System 1 = fast/local processing\n- System 2 = slow/deliberate processing\n- Need seamless handoff between modes\n- Critical for COLLA PSE detection (System 1 takeover)", "length": 960, "added_at": "2026-02-18T03:49:55.056567+00:00", "tacti_relevance": 0.95}
{"id": "e505ab577ad1", "title": "Solve Everything - The Intelligence Revolution Manifesto (2026)", "topic": "arousal", "source": "manual", "url": null, "content": "Solve Everything - The Intelligence Revolution Manifesto (2026)\n\nKEY CONCEPTS:\n- Intelligence Revolution: War on Attention (vs. Ignorance/Muscle/Distance)\n- The Muddle: Current transition period\n- RoCS: Return on Cognitive Spend - new corporate metric\n- Compute Escrow: Renting AI compute resources\n- Replication Pack: Cryptographically signed proof of bug-free code\n- Targeting Authorities: AI-driven bounty systems\n- Action Network: Closed-loop robotic systems that iterate autonomously\n\nTHREE FUTURES:\n1. 2026 - THE LOCK-IN: AI as infrastructure, agents execute, spec-to-artifact\n2. 2030 - THE LIQUEFACTION: Programmable matter, Virtual Cell, biology = software\n3. 2035 - THE QUIET HUM: Solved world, Longevity Escape Velocity, Universal Basic Capability\n\nRELEVANCE TO TACTI(C)-R:\n- AROUSAL: Attention as the scarce resource - parallels TACTI(C)-R framework\n- REPAIRABLE: Self-healing Action Networks\n- COLLABORATION: Human-AI partnership (intent + execution)\n- GOVERNANCE: Targeting Authorities and rails for AI deployment", "length": 1026, "added_at": "2026-02-18T03:52:24.674610+00:00", "tacti_relevance": 0.95}
{"id": "908ef122265f", "title": "Time for Memories - Buzsáki et al. (Journal of Neuroscience 2023)", "topic": "temporality", "source": "manual", "url": null, "content": "Time for Memories - Buzsáki et al. (Journal of Neuroscience 2023)\n\nFull citation: Buzonomano, D. V., Buzsáki, G., Davachi, L., & Nobre, A. C. (2023). Time for Memories. The Journal of Neuroscience, 43(45), 7565–7574.\n\nKEY CONCEPTS:\n- Memory and temporal cognition are inherently linked\n- Working memory and implicit timing may share overlapping neural mechanisms\n- Temporal structure is encoded in associative and episodic memory\n- Neural sequences provide computational motif for timing, working memory, spatiotemporal coding\n\nMAIN ARGUMENT:\n- Memories are about the past but for the future\n- Time is an abstraction for change\n- Neural sequences support both timing and memory\n- The brain uses structured dynamics to organize experiences\n\nTACTI(C)-R RELEVANCE:\n- TEMPORALITY: Ground truth for how brains maintain temporal context\n- Cross-timescale: Neural sequences operate at multiple time scales\n- Supports the need for explicit temporal indexing in AI agents", "length": 962, "added_at": "2026-02-18T04:21:39.486679+00:00", "tacti_relevance": 0.95}
{"id": "1cfb237f80aa", "title": "Persistent Activity During Working Memory - Curtis & Sprague (eLife 2021)", "topic": "cross_timescale", "source": "manual", "url": null, "content": "Persistent Activity During Working Memory - Curtis & Sprague (eLife 2021)\n\nFull citation: Curtis, C. E., & Sprague, T. C. (2021). Persistent activity during working memory from front to back. eLife, 10, e69862.\n\nKEY CONCEPTS:\n- Working memory maintains task-relevant information over delays\n- Prefrontal cortex (PFC) sustains persistent neural activity\n- Distributed mechanisms support active maintenance\n- Front-to-back cortical interactions enable WM\n\nFINDINGS:\n- PFC stores representations during delay periods\n- Parietal cortex contributes to maintenance\n- Timing mechanisms support sustained activity\n- Different brain areas handle different WM aspects\n\nTACTI(C)-R RELEVANCE:\n- CROSS-TIMESCALE: Biological basis for working memory\n- Shows how brain maintains info across time delays\n- Supports hierarchical control architecture\n- Different time constants in different brain regions", "length": 886, "added_at": "2026-02-18T04:21:48.567230+00:00", "tacti_relevance": 0.9}
{"id": "0043ad0099f0", "title": "Neural Representation of Episodic Time - Kwok (Neuroscience & Biobehavioral Reviews 2025)", "topic": "temporality", "source": "manual", "url": null, "content": "Neural Representation of Episodic Time - Kwok (Neuroscience & Biobehavioral Reviews 2025)\n\nFull citation: Kwok, S. C. (2025). Neural representation of episodic time. Neuroscience & Biobehavioral Reviews (PMC).\n\nKEY CONCEPTS:\n- How the brain represents time in episodic memory\n- Temporal contexts bound to memory traces\n- Hippocampal mechanisms for time perception\n- Bridge between perception and memory\n\nTACTI(C)-R RELEVANCE:\n- TEMPORALITY: Neural basis for time-bound episodic memory\n- Shows how temporal context is encoded\n- Supports need for time-indexed storage in AI", "length": 571, "added_at": "2026-02-18T04:21:55.784063+00:00", "tacti_relevance": 0.9}
{"id": "6be87022c3ab", "title": "The Relation of Strength of Stimulus to Rapidity of Habit-Formation - Yerkes & Dodson (1908)", "topic": "arousal", "source": "manual", "url": null, "content": "The Relation of Strength of Stimulus to Rapidity of Habit-Formation - Yerkes & Dodson (1908)\n\nFull citation: Yerkes, R. M., & Dodson, J. D. (1908). The relation of strength of stimulus to rapidity of habit-formation. Journal of Comparative Neurology and Psychology, 18(5), 459-482.\n\nHISTORICAL PAPER:\n- First describing the Yerkes-Dodson law\n- Relationship between arousal and performance\n- Found that moderate stimulation = optimal learning\n- Too weak = no response, Too strong = inhibition\n\nTHE YERKES-DODSON LAW:\n- Inverted U relationship\n- Optimal arousal point for performance\n- Complex tasks require lower arousal for peak performance\n- Simple tasks can handle higher arousal\n\nTACTI(C)-R RELEVANCE:\n- AROUSAL: Foundational psychological principle\n- Explains why AI systems need compute modulation\n- Too much load = degraded performance\n- Basis for adaptive resource allocation", "length": 882, "added_at": "2026-02-18T04:22:04.182342+00:00", "tacti_relevance": 0.95}
{"id": "e0d4f05cca0a", "title": "AI Models Collapse When Trained on Recursively Generated Data - Shumailov et al. (Nature 2024)", "topic": "collapse", "source": "manual", "url": null, "content": "AI Models Collapse When Trained on Recursively Generated Data - Shumailov et al. (Nature 2024)\n\nFull citation: Shumailov, I., Shumaylov, Z., Zhao, Y., Papernot, N., Anderson, R., & Gal, Y. (2024). AI models collapse when trained on recursively generated data. Nature, 631, 755-759.\n\nKEY CONCEPTS:\n- Model collapse is a degenerative learning process\n- When models train on outputs of other models, quality degrades\n- Distribution tails shrink over generations\n- Irreversible if feedback loops continue\n- Affects LLMs, VAEs, GMMs\n\nMECHANISM:\n- Early generations capture distribution accurately\n- Later generations lose rare patterns\n- Model begins to forget original data\n- Eventually produces only common outputs\n\nIMPLICATIONS:\n- Need human-original data to prevent collapse\n- Quality curation is essential\n- Synthetic data requires careful filtering\n- Governance needed for data sourcing\n\nTACTI(C)-R RELEVANCE:\n- COLLAPSE: Direct AI analogue to human burnout/cognitive decline\n- Prevention mirrors human strategies: rest, variety, quality input\n- Supports need for provenance tracking\n- Circuit breakers needed to detect early signs", "length": 1132, "added_at": "2026-02-18T04:22:48.952234+00:00", "tacti_relevance": 0.95}
{"id": "81e5ff0e74b6", "title": "Agentic Design Patterns: A System-Theoretic Framework - 12 agentic design patterns derived from syst", "topic": "architecture", "source": "manual", "url": null, "content": "Agentic Design Patterns: A System-Theoretic Framework - 12 agentic design patterns derived from systems theory and mapped to agentic challenges. Key concepts: layered functional architecture, nested agents, compositional patterns. Directly relevant to TACTI principles.", "length": 269, "added_at": "2026-02-21T04:10:20.195354+00:00", "tacti_relevance": 0.95}
{"id": "200a52f0a1f3", "title": "AI Agents: Evolution, Architecture, and Real-World Applications - arXiv 2025. Modern review of agent", "topic": "architecture", "source": "manual", "url": null, "content": "AI Agents: Evolution, Architecture, and Real-World Applications - arXiv 2025. Modern review of agentic AI including: architectural patterns, evaluation methodologies, implementation patterns. Covers LLM-based agents, tool use, multi-agent systems.", "length": 247, "added_at": "2026-02-21T04:10:24.863827+00:00", "tacti_relevance": 0.9}
{"id": "4098a1adedf9", "title": "Intelligent Agents: Theory and Practice - Wooldridge. Foundational survey on agent theory. Covers: a", "topic": "architecture", "source": "manual", "url": null, "content": "Intelligent Agents: Theory and Practice - Wooldridge. Foundational survey on agent theory. Covers: agent definitions, multi-agent systems, agent architectures, practical implementation issues. Essential for agent theory foundation.", "length": 231, "added_at": "2026-02-21T04:10:39.597460+00:00", "tacti_relevance": 0.85}
{"id": "faaaa88aadd2", "title": "Agent Architecture: An Overview - Chin et al. 2014. Comparative analysis of: reactive, deliberative ", "topic": "architecture", "source": "manual", "url": null, "content": "Agent Architecture: An Overview - Chin et al. 2014. Comparative analysis of: reactive, deliberative (BDI), hybrid, cognitive architectures. Good for understanding architectural paradigms.", "length": 187, "added_at": "2026-02-21T04:10:39.654687+00:00", "tacti_relevance": 0.8}
{"id": "8c2ea69cbcef", "title": "OpenAI Practical Guide to Building Agents - 2024. Contemporary guide for generative-AI agents: tool ", "topic": "architecture", "source": "manual", "url": null, "content": "OpenAI Practical Guide to Building Agents - 2024. Contemporary guide for generative-AI agents: tool integrations, workflow execution, reliability patterns, failure handling.", "length": 173, "added_at": "2026-02-21T04:10:39.711809+00:00", "tacti_relevance": 0.9}
{"id": "ce045a20ee71", "title": "Hybrid Agentic AI and Multi-Agent Systems - arXiv 2025. Combines LLM agents with classical multi-age", "topic": "architecture", "source": "manual", "url": null, "content": "Hybrid Agentic AI and Multi-Agent Systems - arXiv 2025. Combines LLM agents with classical multi-agent systems. Prescriptive Maintenance use case. Relevant to TACTI hybrid architecture.", "length": 185, "added_at": "2026-02-21T04:10:45.642550+00:00", "tacti_relevance": 0.85}
{"id": "525a7a739020", "title": "Designs for Explaining Intelligent Agents - Haynes & Cohen 2009. Building explainability into agent ", "topic": "architecture", "source": "manual", "url": null, "content": "Designs for Explaining Intelligent Agents - Haynes & Cohen 2009. Building explainability into agent mechanisms. Key for human-agent trust and XAI in agentic systems.", "length": 165, "added_at": "2026-02-21T04:10:45.699245+00:00", "tacti_relevance": 0.75}
{"id": "d0da4c32dbd5", "title": "Introduction to the Soar Cognitive Architecture - Laird 2022. Comprehensive tutorial on Soar: produc", "topic": "architecture", "source": "manual", "url": null, "content": "Introduction to the Soar Cognitive Architecture - Laird 2022. Comprehensive tutorial on Soar: production systems, unified theory of cognition, learning, robotics. Essential for understanding classical cognitive architectures.", "length": 225, "added_at": "2026-02-21T04:12:25.644731+00:00", "tacti_relevance": 0.85}
{"id": "0d1c40da25aa", "title": "The dMARS Architecture: Specification of the Distributed Multi-Agent Reasoning System - Wooldridge e", "topic": "architecture", "source": "manual", "url": null, "content": "The dMARS Architecture: Specification of the Distributed Multi-Agent Reasoning System - Wooldridge et al. 2004. Formal specification of PRS-based multi-agent system. Key for understanding BDI agent implementation.", "length": 213, "added_at": "2026-02-21T04:12:25.710373+00:00", "tacti_relevance": 0.8}
{"id": "a663be0aea03", "title": "TACTI(C)-R Framework Integration Document - Synthesizes 14 research papers. Key mappings: 5 function", "topic": "architecture", "source": "manual", "url": null, "content": "TACTI(C)-R Framework Integration Document - Synthesizes 14 research papers. Key mappings: 5 functional subsystems (Reasoning, Perception, Action, Learning, Communication), 12 agentic design patterns, Soar cognitive architecture components (episodic/semantic memory, chunking, impasses), Transformer foundation. Maps all to TACTI principles: Vitality=Arousal, Cognition=Cross-Timescale, Flow=Adaptive Computation, Malleability=Learning, Agency=Repairable.", "length": 454, "added_at": "2026-02-21T04:15:44.609460+00:00", "tacti_relevance": 1.0}
{"id": "a5e8d51a67a5", "title": "IPNB Guidebook 1: Cultivating Individuation through Interpersonal Neurobiology - Practical exercises", "topic": "ipnb", "source": "manual", "url": null, "content": "IPNB Guidebook 1: Cultivating Individuation through Interpersonal Neurobiology - Practical exercises for 9 domains: consciousness (Wheel of Awareness), bilateral integration, vertical integration, memory, narrative, state, interpersonal, temporal, transpirational. Maps directly to TACTI principles.", "length": 299, "added_at": "2026-02-21T06:20:03.137901+00:00", "tacti_relevance": 1.0}
{"id": "a58d83236625", "title": "IPNB Guidebook 2: Integrating Individuated Individuals into Collective Wholeness - The MWe concept (", "topic": "ipnb", "source": "manual", "url": null, "content": "IPNB Guidebook 2: Integrating Individuated Individuals into Collective Wholeness - The MWe concept (me + we). Practical group exercises: attunement, co-regulation, shared narrative, conflict repair, collective purpose. Directly relevant to human-agent collective intelligence.", "length": 276, "added_at": "2026-02-21T06:20:19.768143+00:00", "tacti_relevance": 1.0}
{"id": "accf6c6bdcd2", "title": "IPNB Foundations: Complete guide to Interpersonal Neurobiology - 10 integration nodes: consciousness", "topic": "ipnb", "source": "manual", "url": null, "content": "IPNB Foundations: Complete guide to Interpersonal Neurobiology - 10 integration nodes: consciousness, bilateral, vertical, memory, narrative, state, interpersonal, temporal, transpirational, identity (MWe). Polyvagal theory, attachment, mirror neurons, inter-brain synchrony. Essential for TACTI framework.", "length": 306, "added_at": "2026-02-21T06:20:19.844865+00:00", "tacti_relevance": 1.0}
{"id": "6c8551d3e1dd", "title": "Fine-tuning research: LLM customization, LoRA adapters, domain adaptation, emergent abilities from t", "topic": "fine_tuning", "source": "manual", "url": null, "content": "Fine-tuning research: LLM customization, LoRA adapters, domain adaptation, emergent abilities from training. Relevant to TACTI for agent specialization and skill acquisition.", "length": 174, "added_at": "2026-02-21T12:13:59.873206+00:00", "tacti_relevance": 0.8}
{"id": "274a99c22ad5", "title": "Scalable Matrix Extensions: Matrix multiplication optimization, distributed compute, MoE (Mixture of", "topic": "scalable_matrix", "source": "manual", "url": null, "content": "Scalable Matrix Extensions: Matrix multiplication optimization, distributed compute, MoE (Mixture of Experts), parallel processing for LLM scaling. Relevant to TACTI for computational resource management and efficient inference.", "length": 228, "added_at": "2026-02-21T12:14:15.763099+00:00", "tacti_relevance": 0.8}
